# -*- coding: utf-8 -*-
"""CIFAR-10.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XOx1yjpXleT_KSLpFhmlN_uSFpGcJdNl
"""

import torch
import torchvision
import torchvision.datasets as datasets
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt
import torch.utils.data as Data
import torch.nn.functional as F
import torch.nn as nn

print(torch.__version__)

print(torchvision.__version__)

transform = transforms.Compose(
    [transforms.RandomHorizontalFlip(),transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

cifar_trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform= transform)

transform1 = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

cifar_testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform1)

trainloader = torch.utils.data.DataLoader(cifar_trainset, batch_size=100, shuffle=True)
type(trainloader)

validation_loader = torch.utils.data.DataLoader(cifar_testset, batch_size=100, shuffle=False)
type(trainloader)

classes = ('airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship',' truck' )

data_iter = iter(trainloader)
type(data_iter)

images,labels = data_iter.next()
print(images.shape)

img_data = images[0]
img_data.shape

np_image = img_data.numpy()                      
np_image = np.transpose(np_image, (1,2,0))
np_image = np_image*(0.5, 0.5, 0.5)+(0.5, 0.5, 0.5)       
print(np_image.shape)

plt.figure(figsize = (2,2))
plt.imshow(np_image)
print(classes[labels[0].item()])
plt.show()

_, axs = plt.subplots(1, 8, figsize=(12, 12))
axs = axs.flatten()
for img, ax in zip(images, axs):
  np_image = img.numpy()                      
  np_image = np.transpose(np_image, (1,2,0))
  np_image = np_image*(0.5, 0.5, 0.5)+(0.5, 0.5, 0.5)       
  ax.imshow(np_image)
plt.show()

class Net(nn.Module):
    def __init__(self):
        super(Net, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6, kernel_size=3)
        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=2)
        self.conv2 = nn.Conv2d(6,16,3)
        self.conv3 = nn.Conv2d(16,64,5)
        self.fc1 = nn.Linear(64 * 2 * 2, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)
    def forward(self, x):
      x = self.pool(F.relu(self.conv1(x)))
      x = self.pool(F.relu(self.conv2(x)))
      x = (F.relu(self.conv3(x)))
      x = x.view(-1, 64 * 2 * 2)
      x = F.relu(self.fc1(x))
      x = F.relu(self.fc2(x))
      x = self.fc3(x)
      return(x)

model = Net()
model

y = model(images)
print(y.shape)

criteria = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
loss_list = []
acc_list = []
val_list=[]
valoss_list = []

for e in range(100):
  loss_net= 0
  acc_net = 0 
  val_acc = 0
  val_loss = 0
  for images, labels in trainloader:
    images = images
    labels = labels
    pred = model(images)
    loss = criteria(pred,labels)
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    _, pred = torch.max(pred,1)
    loss_net += loss.item()
    acc_net += torch.sum(pred == labels.data)
  else:
    with torch.no_grad(): #we dont want to update gradient from validation set
      for images, labels in validation_loader:
        images = images
        labels = labels
        pred = model(images)
        
        loss_val = criteria(pred,labels)
        _, pred = torch.max(pred,1)
        val_loss += loss_val.item()
        val_acc += torch.sum(pred==labels.data)
  val_loss /= len(validation_loader)
  valoss_list.append(val_loss)
  val_acc = val_acc.float()/len(validation_loader)
  val_list.append(val_acc)
  loss_net /= len(trainloader)
  acc_net = acc_net.float()/len(trainloader)
  loss_list.append(loss_net)
  acc_list.append(acc_net)
  print("Epoch:",e,"loss: ", loss_net, "acc:", acc_net.item(), "Val Acc: ", val_acc.item(), "Val_loss: ", val_loss)

plt.plot(loss_list, label ='Training Loss')



plt.plot(valoss_list, label = 'Validation loss')
plt.legend()

plt.plot(acc_list, label ='Training Acc')



plt.plot(val_list, label = 'Validation Acc')
plt.legend()

